{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18cbf7de",
   "metadata": {},
   "source": [
    "# Decision Tree From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51cf6b17-248f-48cc-bdaf-6c924500b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b00c2a-ae0c-4261-b494-8490a228bdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>21</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>16</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>female</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>14</td>\n",
       "      <td>289700</td>\n",
       "      <td>4.83</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>75+ years</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>4.59</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>G.I. Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34 years</td>\n",
       "      <td>9</td>\n",
       "      <td>274300</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Boomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year     sex          age  suicides_no  population  \\\n",
       "0  Albania  1987    male  15-24 years           21      312900   \n",
       "1  Albania  1987    male  35-54 years           16      308000   \n",
       "2  Albania  1987  female  15-24 years           14      289700   \n",
       "3  Albania  1987    male    75+ years            1       21800   \n",
       "4  Albania  1987    male  25-34 years            9      274300   \n",
       "\n",
       "   suicides/100k pop country-year  HDI for year  gdp_for_year ($)   \\\n",
       "0               6.71  Albania1987           NaN      2,156,624,900   \n",
       "1               5.19  Albania1987           NaN      2,156,624,900   \n",
       "2               4.83  Albania1987           NaN      2,156,624,900   \n",
       "3               4.59  Albania1987           NaN      2,156,624,900   \n",
       "4               3.28  Albania1987           NaN      2,156,624,900   \n",
       "\n",
       "   gdp_per_capita ($)       generation  \n",
       "0                 796     Generation X  \n",
       "1                 796           Silent  \n",
       "2                 796     Generation X  \n",
       "3                 796  G.I. Generation  \n",
       "4                 796          Boomers  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data from kaggle\n",
    "# https://www.kaggle.com/datasets/russellyates88/suicide-rates-overview-1985-to-2016/download\n",
    "\n",
    "raw_df = pd.read_csv('../../data/suicide.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb48860",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8242f3a4-56e8-4efb-b40c-a19c77a00dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'sex', 'age', 'suicides_no', 'population',\n",
       "       'suicides/100k pop', 'country-year', 'HDI for year', 'gdp_for_year ($)',\n",
       "       'gdp_per_capita ($)', 'generation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove spaces from coloumn name\n",
    "raw_df.rename(columns={' gdp_for_year ($) ':'gdp_for_year ($)'}, inplace=True)\n",
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70ca91",
   "metadata": {},
   "source": [
    "One main issue with the data is the 'HDI for year' column. This feature is the Human Development Index, which could have a notable effect on the suicide risk of a population. However, there is a significant amount of rows missing entries for this column. Therefore we decided to remove it altogether so as to not skew the learning ability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c833dc91-5e4d-491a-a70c-373b0ac7ea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27688</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27700</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27712</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27724</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27748</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1624 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  year\n",
       "0         Albania  1987\n",
       "12        Albania  1988\n",
       "24        Albania  1989\n",
       "36        Albania  1992\n",
       "48        Albania  1993\n",
       "...           ...   ...\n",
       "27688  Uzbekistan  2001\n",
       "27700  Uzbekistan  2002\n",
       "27712  Uzbekistan  2003\n",
       "27724  Uzbekistan  2004\n",
       "27748  Uzbekistan  2009\n",
       "\n",
       "[1624 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop na values in HDI\n",
    "raw_df.loc[raw_df['HDI for year'].isna(), ['country', 'year']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20722a82-31d8-4c03-981f-59df7e656cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'sex', 'age', 'suicides_no', 'population',\n",
       "       'suicides/100k pop', 'HDI for year', 'gdp_for_year ($)',\n",
       "       'gdp_per_capita ($)', 'generation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still missing a lot of HDI data\n",
    "# Decided to drop column so as to not skew results due to missing information in some rows\n",
    "raw_df.drop([\"HDI for year\"], axis=1)\n",
    "\n",
    "# Also drop country-year since it is already given in the year column\n",
    "raw_df.drop(columns=['country-year'], inplace=True)\n",
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fdb5d",
   "metadata": {},
   "source": [
    "Now that the data has been scrubbed, we need to create columns for our class which is the risk of suicide. For each row, if the value of 'suicides/100k' is greater than the mean of 'suicides/100k' for all rows then we'll call that a 'high' risk, if the value is less than the mean it will be labeled a 'low' risk. This will be the target column for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132963c7-bcba-4627-a907-214135dd6090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19061\n",
       "1     8759\n",
       "Name: suicide_risk, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The scratch model requires binary values for classification\n",
    "# Create additional column for suicide risk and set the default value as low == 0\n",
    "raw_df['suicide_risk'] = 0 \n",
    "\n",
    "# Set the risk as high if suicides/100k pop is higher than the mean, high == 1\n",
    "# Compare the value of suicides/100k to the mean of all suicides/100k.\n",
    "# If the value is lower than the mean we'll say it is a low risk (0), else a high risk (1)\n",
    "\n",
    "raw_df.loc[raw_df['suicides/100k pop'] > raw_df['suicides/100k pop'].mean(), 'suicide_risk'] = 1 \n",
    "raw_df['suicide_risk'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db77ecb",
   "metadata": {},
   "source": [
    "Since we have time series data and are attempting to build a machine learning model to make predictions on the future, we need to train the model on past observations. Therefore, instead of doing a randomized 80%|10%|10% train test validate split, we will split the data by time. By taking the cumulative sum / sum of years of all the data, we can see what percentage of the data hs been collected up until a particular year. Observe the list below: ~80% of the data represents years 1985 - 2009, the next ~10% is from 2010 - 2013, and the final ~10% from 2014 - 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd61b04-a98b-40f3-9783-dd50e8a1aa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985      2.070453\n",
       "1986      4.140906\n",
       "1987      6.470165\n",
       "1988      8.583753\n",
       "1989     10.826743\n",
       "1990     13.587347\n",
       "1991     16.347951\n",
       "1992     19.151689\n",
       "1993     21.955428\n",
       "1994     24.888569\n",
       "1995     28.253055\n",
       "1996     31.574407\n",
       "1997     34.895758\n",
       "1998     38.303379\n",
       "1999     41.883537\n",
       "2000     45.593098\n",
       "2001     49.388929\n",
       "2002     53.098490\n",
       "2003     56.808052\n",
       "2004     60.431344\n",
       "2005     64.054637\n",
       "2006     67.721064\n",
       "2007     71.430625\n",
       "2008     75.097052\n",
       "2009     78.936017\n",
       "2010     82.731848\n",
       "2011     86.441409\n",
       "2012     89.935298\n",
       "2013     93.386053\n",
       "2014     96.750539\n",
       "2015     99.424874\n",
       "2016    100.000000\n",
       "Name: year, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a series containing number of data per year\n",
    "year_dt = raw_df.year.value_counts()\n",
    "year_dt.sort_index(inplace=True)\n",
    "cum_pct = 100 * year_dt.cumsum() / year_dt.sum()\n",
    "cum_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0cf2113-ab8c-4cdc-8e3c-1d04df934bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape:  (21960, 12)\n",
      "val_df.shape:  (3060, 12)\n",
      "test_df.shape:  (2800, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split data into 80/10/10\n",
    "\n",
    "train_df = raw_df.loc[raw_df['year'] <= 2009]\n",
    "val_df = raw_df.loc[(raw_df['year'] >= 2010) & (raw_df['year'] <=2012)]\n",
    "test_df = raw_df.loc[raw_df['year'] >= 2013]\n",
    "\n",
    "print('train_df.shape: ', train_df.shape)\n",
    "print('val_df.shape: ', val_df.shape)\n",
    "print('test_df.shape: ', test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68b874",
   "metadata": {},
   "source": [
    "Noting the correlellogram from earlier, the following columns won't be useful for the algorithm:\n",
    "year, suicides_no, population, suicides/100k, gpd_for_year, and generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a016c300-922d-4d97-975e-d82b12606549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label input and target columns\n",
    "input_cols = ['country', 'sex', 'age', 'gdp_per_capita ($)']\n",
    "target_col = 'suicide_risk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e61e3de-e511-45a8-954e-4f164a2ef802",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = train_df.loc[:, input_cols]\n",
    "train_target = train_df.loc[:, target_col]\n",
    "\n",
    "val_inputs = val_df.loc[:, input_cols]\n",
    "val_target = val_df.loc[:, target_col]\n",
    "\n",
    "test_inputs = test_df.loc[:, input_cols]\n",
    "test_target = test_df.loc[:, target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f1ee0fa-2088-4c24-a892-1acc750c77c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = list(train_inputs.select_dtypes(include=np.number).columns)\n",
    "categorical_cols = list(train_inputs.select_dtypes(include='object').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d155d0",
   "metadata": {},
   "source": [
    "The numeric features identified in the previous step need to scaled to values from 0 to 1 to prevent particular features from having a disproportionate affect on the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dfbd5d0-d8fe-4cac-94f1-81f0619a9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Fit the scaler to all the data\n",
    "scaler = MinMaxScaler().fit(raw_df.loc[:, numeric_cols])\n",
    "\n",
    "# Scale the train, validation and test sets \n",
    "train_inputs.loc[:, numeric_cols] = scaler.transform(train_inputs.loc[:, numeric_cols])\n",
    "val_inputs.loc[:, numeric_cols] = scaler.transform(val_inputs.loc[:, numeric_cols])\n",
    "test_inputs.loc[:, numeric_cols] = scaler.transform(test_inputs.loc[:, numeric_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3fde80-1c7e-4bd1-b127-111a566035f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.111703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.126815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.020373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.057252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.178032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.960056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gdp_per_capita ($)\n",
       "count        21960.000000\n",
       "mean             0.111703\n",
       "std              0.126815\n",
       "min              0.000000\n",
       "25%              0.020373\n",
       "50%              0.057252\n",
       "75%              0.178032\n",
       "max              0.960056"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ce8f5",
   "metadata": {},
   "source": [
    "Finally, we need to encode the categorical columns into values of either 0 or 1 in order to use them in the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723199d7-0b51-46a2-9aeb-50d9df8bc543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country    101\n",
       "sex          2\n",
       "age          6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values of each categorical column\n",
    "raw_df[categorical_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15b3f616-44ca-43c6-8730-36b0ac8641d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore').fit(raw_df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde52400-be73-4242-a48f-cb5c90883724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/env-01/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n",
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/2917261160.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()\n"
     ]
    }
   ],
   "source": [
    "encoded_cols = list(encoder.get_feature_names(categorical_cols))\n",
    "\n",
    "# Encode the columns\n",
    "train_inputs[encoded_cols] = encoder.transform(train_inputs.loc[:, categorical_cols]).toarray()\n",
    "val_inputs[encoded_cols] = encoder.transform(val_inputs.loc[:, categorical_cols]).toarray()\n",
    "test_inputs[encoded_cols] = encoder.transform(test_inputs.loc[:, categorical_cols]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5594a831-e29c-42c3-91e0-7c67f416ed3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>country_Albania</th>\n",
       "      <th>country_Antigua and Barbuda</th>\n",
       "      <th>country_Argentina</th>\n",
       "      <th>country_Armenia</th>\n",
       "      <th>country_Aruba</th>\n",
       "      <th>country_Australia</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Uruguay</th>\n",
       "      <th>country_Uzbekistan</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>age_15-24 years</th>\n",
       "      <th>age_25-34 years</th>\n",
       "      <th>age_35-54 years</th>\n",
       "      <th>age_5-14 years</th>\n",
       "      <th>age_55-74 years</th>\n",
       "      <th>age_75+ years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>female</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>male</td>\n",
       "      <td>75+ years</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34 years</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27755</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>female</td>\n",
       "      <td>75+ years</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27756</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>female</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27757</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>female</td>\n",
       "      <td>55-74 years</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27758</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>male</td>\n",
       "      <td>5-14 years</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27759</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>female</td>\n",
       "      <td>5-14 years</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21960 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country     sex          age  gdp_per_capita ($)  country_Albania  \\\n",
       "0         Albania    male  15-24 years            0.004322              1.0   \n",
       "1         Albania    male  35-54 years            0.004322              1.0   \n",
       "2         Albania  female  15-24 years            0.004322              1.0   \n",
       "3         Albania    male    75+ years            0.004322              1.0   \n",
       "4         Albania    male  25-34 years            0.004322              1.0   \n",
       "...           ...     ...          ...                 ...              ...   \n",
       "27755  Uzbekistan  female    75+ years            0.008572              0.0   \n",
       "27756  Uzbekistan  female  35-54 years            0.008572              0.0   \n",
       "27757  Uzbekistan  female  55-74 years            0.008572              0.0   \n",
       "27758  Uzbekistan    male   5-14 years            0.008572              0.0   \n",
       "27759  Uzbekistan  female   5-14 years            0.008572              0.0   \n",
       "\n",
       "       country_Antigua and Barbuda  country_Argentina  country_Armenia  \\\n",
       "0                              0.0                0.0              0.0   \n",
       "1                              0.0                0.0              0.0   \n",
       "2                              0.0                0.0              0.0   \n",
       "3                              0.0                0.0              0.0   \n",
       "4                              0.0                0.0              0.0   \n",
       "...                            ...                ...              ...   \n",
       "27755                          0.0                0.0              0.0   \n",
       "27756                          0.0                0.0              0.0   \n",
       "27757                          0.0                0.0              0.0   \n",
       "27758                          0.0                0.0              0.0   \n",
       "27759                          0.0                0.0              0.0   \n",
       "\n",
       "       country_Aruba  country_Australia  ...  country_Uruguay  \\\n",
       "0                0.0                0.0  ...              0.0   \n",
       "1                0.0                0.0  ...              0.0   \n",
       "2                0.0                0.0  ...              0.0   \n",
       "3                0.0                0.0  ...              0.0   \n",
       "4                0.0                0.0  ...              0.0   \n",
       "...              ...                ...  ...              ...   \n",
       "27755            0.0                0.0  ...              0.0   \n",
       "27756            0.0                0.0  ...              0.0   \n",
       "27757            0.0                0.0  ...              0.0   \n",
       "27758            0.0                0.0  ...              0.0   \n",
       "27759            0.0                0.0  ...              0.0   \n",
       "\n",
       "       country_Uzbekistan  sex_female  sex_male  age_15-24 years  \\\n",
       "0                     0.0         0.0       1.0              1.0   \n",
       "1                     0.0         0.0       1.0              0.0   \n",
       "2                     0.0         1.0       0.0              1.0   \n",
       "3                     0.0         0.0       1.0              0.0   \n",
       "4                     0.0         0.0       1.0              0.0   \n",
       "...                   ...         ...       ...              ...   \n",
       "27755                 1.0         1.0       0.0              0.0   \n",
       "27756                 1.0         1.0       0.0              0.0   \n",
       "27757                 1.0         1.0       0.0              0.0   \n",
       "27758                 1.0         0.0       1.0              0.0   \n",
       "27759                 1.0         1.0       0.0              0.0   \n",
       "\n",
       "       age_25-34 years  age_35-54 years  age_5-14 years  age_55-74 years  \\\n",
       "0                  0.0              0.0             0.0              0.0   \n",
       "1                  0.0              1.0             0.0              0.0   \n",
       "2                  0.0              0.0             0.0              0.0   \n",
       "3                  0.0              0.0             0.0              0.0   \n",
       "4                  1.0              0.0             0.0              0.0   \n",
       "...                ...              ...             ...              ...   \n",
       "27755              0.0              0.0             0.0              0.0   \n",
       "27756              0.0              1.0             0.0              0.0   \n",
       "27757              0.0              0.0             0.0              1.0   \n",
       "27758              0.0              0.0             1.0              0.0   \n",
       "27759              0.0              0.0             1.0              0.0   \n",
       "\n",
       "       age_75+ years  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                1.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "27755            1.0  \n",
       "27756            0.0  \n",
       "27757            0.0  \n",
       "27758            0.0  \n",
       "27759            0.0  \n",
       "\n",
       "[21960 rows x 113 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef2fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_inputs[numeric_cols + encoded_cols]\n",
    "X_val = val_inputs[numeric_cols + encoded_cols]\n",
    "X_test = test_inputs[numeric_cols + encoded_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecd01e",
   "metadata": {},
   "source": [
    "### Decison Tree from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de77d987-01c3-4eb8-980a-9f27ac4e51f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def debug(self, feature_names, class_names, show_details=True):\n",
    "        \"\"\"Print ASCII visualization of decision tree.\"\"\"\n",
    "        self.tree_.debug(feature_names, class_names, show_details)\n",
    "\n",
    "    def _gini(self, y):\n",
    "        \"\"\"Compute Gini impurity of a non-empty node.\n",
    "        Gini impurity is defined as Σ p(1-p) over all classes, with p the frequency of a\n",
    "        class within the node. Since Σ p = 1, this is equivalent to 1 - Σ p^2.\n",
    "        \"\"\"\n",
    "        m = y.size\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(self.n_classes_))\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"Find the best split for a node.\n",
    "        \"Best\" means that the average impurity of the two children, weighted by their\n",
    "        population, is the smallest possible. Additionally it must be less than the\n",
    "        impurity of the current node.\n",
    "        To find the best split, we loop through all the features, and consider all the\n",
    "        midpoints between adjacent training samples as possible thresholds. We compute\n",
    "        the Gini impurity of the split generated by that particular feature/threshold\n",
    "        pair, and return the pair with smallest impurity.\n",
    "        Returns:\n",
    "            best_idx: Index of the feature for best split, or None if no split is found.\n",
    "            best_thr: Threshold to use for the split, or None if no split is found.\n",
    "        \"\"\"\n",
    "        # Need at least two elements to split a node.\n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        # Count of each class in the current node.\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "\n",
    "        # Gini of current node.\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        # Loop through all features.\n",
    "        for idx in range(self.n_features_):\n",
    "            # Sort data along selected feature.\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "\n",
    "            # We could actually split the node according to each feature/threshold pair\n",
    "            # and count the resulting population for each class in the children, but\n",
    "            # instead we compute them in an iterative fashion, making this for loop\n",
    "            # linear rather than quadratic.\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):  # possible split positions\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "\n",
    "                # The Gini impurity of a split is the weighted average of the Gini\n",
    "                # impurity of the children.\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                # The following condition is to make sure we don't try to split two\n",
    "                # points with identical values for that feature, as it is impossible\n",
    "                # (both have to end up on the same side of a split).\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2  # midpoint\n",
    "\n",
    "        return best_idx, best_thr\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        \"\"\"Predict class for a single sample.\"\"\"\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build decision tree classifier.\"\"\"\n",
    "        self.n_classes_ = len(set(y))  # classes are assumed to go from 0 to n-1\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        \"\"\"Build a decision tree by recursively finding the best split.\"\"\"\n",
    "        # Population for each class in current node. The predicted class is the one with\n",
    "        # largest population.\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(\n",
    "            gini=self._gini(y),\n",
    "            num_samples=y.size,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "\n",
    "        # Split recursively until maximum depth is reached.\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "    \n",
    "class Node:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "     \n",
    "    def debug(self, feature_names, class_names, show_details):\n",
    "        \"\"\"Print an ASCII visualization of the tree.\"\"\"\n",
    "        lines, _, _, _ = self._debug_aux(\n",
    "            feature_names, class_names, show_details, root=True\n",
    "        )\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "    def _debug_aux(self, feature_names, class_names, show_details, root=False):\n",
    "        # See https://stackoverflow.com/a/54074933/1143396 for similar code.\n",
    "        is_leaf = not self.right\n",
    "        if is_leaf:\n",
    "            lines = [class_names[self.predicted_class]]\n",
    "        else:\n",
    "            lines = [\n",
    "                \"{} < {:.2f}\".format(feature_names[self.feature_index], self.threshold)\n",
    "            ]\n",
    "        if show_details:\n",
    "            lines += [\n",
    "                \"gini = {:.2f}\".format(self.gini),\n",
    "                \"samples = {}\".format(self.num_samples),\n",
    "                str(self.num_samples_per_class),\n",
    "            ]\n",
    "        width = max(len(line) for line in lines)\n",
    "        height = len(lines)\n",
    "        if is_leaf:\n",
    "            lines = [\"║ {:^{width}} ║\".format(line, width=width) for line in lines]\n",
    "            lines.insert(0, \"╔\" + \"═\" * (width + 2) + \"╗\")\n",
    "            lines.append(\"╚\" + \"═\" * (width + 2) + \"╝\")\n",
    "        else:\n",
    "            lines = [\"│ {:^{width}} │\".format(line, width=width) for line in lines]\n",
    "            lines.insert(0, \"┌\" + \"─\" * (width + 2) + \"┐\")\n",
    "            lines.append(\"└\" + \"─\" * (width + 2) + \"┘\")\n",
    "            lines[-2] = \"┤\" + lines[-2][1:-1] + \"├\"\n",
    "        width += 4  # for padding\n",
    "\n",
    "        if is_leaf:\n",
    "            middle = width // 2\n",
    "            lines[0] = lines[0][:middle] + \"╧\" + lines[0][middle + 1 :]\n",
    "            return lines, width, height, middle\n",
    "\n",
    "        # If not a leaf, must have two children.\n",
    "        left, n, p, x = self.left._debug_aux(feature_names, class_names, show_details)\n",
    "        right, m, q, y = self.right._debug_aux(feature_names, class_names, show_details)\n",
    "        top_lines = [n * \" \" + line + m * \" \" for line in lines[:-2]]\n",
    "        # fmt: off\n",
    "        middle_line = x * \" \" + \"┌\" + (n - x - 1) * \"─\" + lines[-2] + y * \"─\" + \"┐\" + (m - y - 1) * \" \"\n",
    "        bottom_line = x * \" \" + \"│\" + (n - x - 1) * \" \" + lines[-1] + y * \" \" + \"│\" + (m - y - 1) * \" \"\n",
    "        # fmt: on\n",
    "        if p < q:\n",
    "            left += [n * \" \"] * (q - p)\n",
    "        elif q < p:\n",
    "            right += [m * \" \"] * (p - q)\n",
    "        zipped_lines = zip(left, right)\n",
    "        lines = (\n",
    "            top_lines\n",
    "            + [middle_line, bottom_line]\n",
    "            + [a + width * \" \" + b for a, b in zipped_lines]\n",
    "        )\n",
    "        middle = n + width // 2\n",
    "        if not root:\n",
    "            lines[0] = lines[0][:middle] + \"┴\" + lines[0][middle + 1 :]\n",
    "        return lines, n + m + width, max(p, q) + 2 + len(top_lines), middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "202c8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframes to numpy arrays for decision tree from scratch\n",
    "X_train_np = X_train.to_numpy()\n",
    "X_val_np = X_val.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n",
    "\n",
    "train_target_np = train_target.to_numpy()\n",
    "val_target_np = val_target.to_numpy()\n",
    "test_target_np = test_target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b39dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/ybx0qpc17lgbs28t98mp2wk40000gn/T/ipykernel_39069/3320118968.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:50% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:50% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6def8",
   "metadata": {},
   "source": [
    "Create and train a decision tree model. Used a function from stack overflow to visualize the data. We can observe similar results to the sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "043c8605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              ┌────────────────────┐                                                             \n",
      "                                                              │ sex_female  < 0.50 │                                                             \n",
      "                                                              │    gini = 0.44     │                                                             \n",
      "                                                              │  samples = 21960   │                                                             \n",
      "                               ┌──────────────────────────────┤   [14875, 7085]    ├──────────────────────────────┐                              \n",
      "                               │                              └────────────────────┘                              │                              \n",
      "                  ┌────────────┴───────────┐                                                          ┌───────────┴───────────┐                  \n",
      "                  │ age_5-14 years  < 0.50 │                                                          │ age_75+ years  < 0.50 │                  \n",
      "                  │      gini = 0.50       │                                                          │      gini = 0.21      │                  \n",
      "                  │    samples = 10980     │                                                          │    samples = 10980    │                  \n",
      "         ┌────────┤      [5237, 5743]      ├─────────┐                                       ┌────────┤     [9638, 1342]      ├─────────┐        \n",
      "         │        └────────────────────────┘         │                                       │        └───────────────────────┘         │        \n",
      "╔════════╧═══════╗                          ╔════════╧═══════╗                      ╔════════╧═══════╗                         ╔════════╧═══════╗\n",
      "║ Suicide Risk 1 ║                          ║ Suicide Risk 0 ║                      ║ Suicide Risk 0 ║                         ║ Suicide Risk 0 ║\n",
      "║  gini = 0.47   ║                          ║  gini = 0.00   ║                      ║  gini = 0.16   ║                         ║  gini = 0.42   ║\n",
      "║ samples = 9150 ║                          ║ samples = 1830 ║                      ║ samples = 9150 ║                         ║ samples = 1830 ║\n",
      "║  [3408, 5742]  ║                          ║   [1829, 1]    ║                      ║  [8353, 797]   ║                         ║  [1285, 545]   ║\n",
      "╚════════════════╝                          ╚════════════════╝                      ╚════════════════╝                         ╚════════════════╝\n"
     ]
    }
   ],
   "source": [
    "## Train decision tree model\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "tree.fit(X_train_np, train_target_np)\n",
    "\n",
    "# Visualize.\n",
    "tree.debug(\n",
    "    feature_names=[\"{} \".format(X_train.columns[i]) for i in range(0, 110)],\n",
    "    class_names=[\"Suicide Risk {}\".format(i) for i in range(0, 2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf823bd",
   "metadata": {},
   "source": [
    "Compute accuracy for train, test and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b585f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7836520947176685\n"
     ]
    }
   ],
   "source": [
    "## Accuracy for train set\n",
    "train_pred = tree.predict(X_train_np)\n",
    "total = len(train_pred)\n",
    "correct = 0\n",
    "\n",
    "for i in range(0, total):\n",
    "    if train_pred[i] == train_target_np[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy = {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b3d6eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.792156862745098\n"
     ]
    }
   ],
   "source": [
    "## Accuracy for val set\n",
    "pred2 = tree.predict(X_val_np)\n",
    "\n",
    "total = len(pred2)\n",
    "correct = 0\n",
    "\n",
    "for i in range(0, total):\n",
    "    if pred2[i] == val_target_np[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy = {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2d37c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7946428571428571\n"
     ]
    }
   ],
   "source": [
    "## Accuracy for test set\n",
    "pred3 = tree.predict(X_test_np)\n",
    "\n",
    "total = len(pred3)\n",
    "correct = 0\n",
    "\n",
    "for i in range(0, total):\n",
    "    if pred3[i] == test_target_np[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy = {correct/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88d67e",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Let's see if we can improve the model's accuracy by doing hyperparamter testing on the max tree depth. A tree that is too deep will be overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f561300c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb Cell 38'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000037?line=13'>14</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000037?line=14'>15</a>\u001b[0m tree \u001b[39m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[39m=\u001b[39mi)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000037?line=15'>16</a>\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X_train_np, train_target_np)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000037?line=16'>17</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000037?line=17'>18</a>\u001b[0m fit_time\u001b[39m.\u001b[39mappend(end \u001b[39m-\u001b[39m start);\n",
      "\u001b[1;32m/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb Cell 28'\u001b[0m in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=95'>96</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y))  \u001b[39m# classes are assumed to go from 0 to n-1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=96'>97</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=97'>98</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X, y)\n",
      "\u001b[1;32m/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb Cell 28'\u001b[0m in \u001b[0;36mDecisionTreeClassifier._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=120'>121</a>\u001b[0m         node\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m thr\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=121'>122</a>\u001b[0m         node\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X_left, y_left, depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=122'>123</a>\u001b[0m         node\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X_right, y_right, depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "\u001b[1;32m/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb Cell 28'\u001b[0m in \u001b[0;36mDecisionTreeClassifier._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=119'>120</a>\u001b[0m         node\u001b[39m.\u001b[39mfeature_index \u001b[39m=\u001b[39m idx\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=120'>121</a>\u001b[0m         node\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m thr\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=121'>122</a>\u001b[0m         node\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X_left, y_left, depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=122'>123</a>\u001b[0m         node\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X_right, y_right, depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "\u001b[1;32m/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb Cell 28'\u001b[0m in \u001b[0;36mDecisionTreeClassifier._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=119'>120</a>\u001b[0m         node\u001b[39m.\u001b[39mfeature_index \u001b[39m=\u001b[39m idx\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=120'>121</a>\u001b[0m         node\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m thr\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=121'>122</a>\u001b[0m         node\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X_left, y_left, depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=122'>123</a>\u001b[0m         node\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X_right, y_right, depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "    \u001b[0;31m[... skipping similar frames: DecisionTreeClassifier._grow_tree at line 122 (2 times)]\u001b[0m\n",
      "\u001b[1;32m/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb Cell 28'\u001b[0m in \u001b[0;36mDecisionTreeClassifier._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=119'>120</a>\u001b[0m         node\u001b[39m.\u001b[39mfeature_index \u001b[39m=\u001b[39m idx\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=120'>121</a>\u001b[0m         node\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m thr\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=121'>122</a>\u001b[0m         node\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X_left, y_left, depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=122'>123</a>\u001b[0m         node\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X_right, y_right, depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "\u001b[1;32m/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb Cell 28'\u001b[0m in \u001b[0;36mDecisionTreeClassifier._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=112'>113</a>\u001b[0m \u001b[39m# Split recursively until maximum depth is reached.\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=113'>114</a>\u001b[0m \u001b[39mif\u001b[39;00m depth \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=114'>115</a>\u001b[0m     idx, thr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_best_split(X, y)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=115'>116</a>\u001b[0m     \u001b[39mif\u001b[39;00m idx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=116'>117</a>\u001b[0m         indices_left \u001b[39m=\u001b[39m X[:, idx] \u001b[39m<\u001b[39m thr\n",
      "\u001b[1;32m/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb Cell 28'\u001b[0m in \u001b[0;36mDecisionTreeClassifier._best_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=55'>56</a>\u001b[0m num_right[c] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=56'>57</a>\u001b[0m gini_left \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m \u001b[39msum\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=57'>58</a>\u001b[0m     (num_left[x] \u001b[39m/\u001b[39m i) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=58'>59</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=59'>60</a>\u001b[0m gini_right \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m \u001b[39msum\u001b[39m(\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=60'>61</a>\u001b[0m     (num_right[x] \u001b[39m/\u001b[39m (m \u001b[39m-\u001b[39m i)) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_classes_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=61'>62</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=63'>64</a>\u001b[0m \u001b[39m# The Gini impurity of a split is the weighted average of the Gini\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=64'>65</a>\u001b[0m \u001b[39m# impurity of the children.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacob/src/COSC311/Project2/source/dtree/ScratchDecisionTree.ipynb#ch0000027?line=65'>66</a>\u001b[0m gini \u001b[39m=\u001b[39m (i \u001b[39m*\u001b[39m gini_left \u001b[39m+\u001b[39m (m \u001b[39m-\u001b[39m i) \u001b[39m*\u001b[39m gini_right) \u001b[39m/\u001b[39m m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparamter testing\n",
    "# We learned from the scikit learn decision tree that the max depth is 42\n",
    "# Let's test from a minimum depth of 2, incrementing by 2 to 42 to see the best accuracy\n",
    "import time\n",
    "\n",
    "train_accuracy_list = []\n",
    "val_accuracy_list = []\n",
    "fit_time = []\n",
    "train_pred_time = []\n",
    "val_pred_time = []\n",
    "\n",
    "for i in range(2, 43, 2):\n",
    "    # fit tree on train\n",
    "    start = time.perf_counter()\n",
    "    tree = DecisionTreeClassifier(max_depth=i)\n",
    "    tree.fit(X_train_np, train_target_np)\n",
    "    end = time.perf_counter()\n",
    "    fit_time.append(end - start);\n",
    "    \n",
    "    # predict on train\n",
    "    start = time.perf_counter()\n",
    "    train_pred = tree.predict(X_train_np)\n",
    "    end = time.perf_counter()\n",
    "    train_pred_time.append(end - start);\n",
    "    \n",
    "    # predict on val\n",
    "    start = time.perf_counter()\n",
    "    val_pred = tree.predict(X_val_np)\n",
    "    end = time.perf_counter()\n",
    "    val_pred_time.append(end - start);\n",
    "    \n",
    "    # calculate train accuracy\n",
    "    total = len(train_pred)\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(0, total):\n",
    "        if train_pred[i] == train_target_np[i]:\n",
    "            correct += 1\n",
    "\n",
    "    train_accuracy_list.append(correct/total)\n",
    "    \n",
    "    # calculate val accuracy\n",
    "    total = len(val_pred)\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(0, total):\n",
    "        if val_pred[i] == val_target_np[i]:\n",
    "            correct += 1\n",
    "\n",
    "    val_accuracy_list.append(correct/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfe723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max \n",
    "maximum = max(val_accuracy_list)\n",
    "pos = val_accuracy_list.index(maximum)\n",
    "print(f\"Tree depth with highest accuracy on validate = {(pos + 1)*2}, accuracy = {maximum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training accuracy at {(pos + 1)*2} = {train_accuracy_list[pos]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "x_ticks = list(range(2, 43, 2))\n",
    "plt.plot(x_ticks, train_accuracy_list);\n",
    "plt.plot(x_ticks, val_accuracy_list);\n",
    "\n",
    "# Annotate the training error and validation error \n",
    "plt.axvline(x=(pos + 1)*2, color='r', linestyle='--')\n",
    "plt.annotate(f'validation acc: {val_accuracy_list[pos]}',\n",
    "            xy=((pos + 2)*2, val_accuracy_list[pos] - .002),\n",
    "            xycoords='data',\n",
    "            fontsize=12,\n",
    "            xytext=(10, 10),\n",
    "            textcoords='offset points',\n",
    "            arrowprops=dict(arrowstyle=\"->\", color='black',\n",
    "                            connectionstyle=\"arc3\"));\n",
    "plt.annotate(f'train acc: {train_accuracy_list[pos]}',\n",
    "            xy=((pos + 1)*2, train_accuracy_list[pos]-.001),\n",
    "            xycoords='data',\n",
    "            fontsize=12,\n",
    "            xytext=(10, 10),\n",
    "            textcoords='offset points',\n",
    "            arrowprops=dict(arrowstyle=\"->\", color='black',\n",
    "                            connectionstyle=\"arc3\"));\n",
    "plt.title(\"Hyperparamter Testing: Training vs Validation Accuracy\");\n",
    "plt.ylabel('Prediction Accuracy');\n",
    "plt.xlabel('Max Tree Depth');\n",
    "plt.legend(['Training', 'Validation']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748f38c",
   "metadata": {},
   "source": [
    "In the graph above we can clearly see that the accuracy increases (error decreases) as the depth increases. However, the graph below shows the performance hit taken in respect to tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Decision Tree Run Time vs Depth\")\n",
    "plt.ylabel('Time (s)');\n",
    "plt.xlabel('Max Tree Depth');\n",
    "x_ticks = list(range(2, 43, 2))\n",
    "plt.plot(x_ticks, fit_time);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "x_ticks = list(range(2, 43, 2))\n",
    "#plt.plot(x_ticks, fit_time);\n",
    "plt.plot(x_ticks, train_pred_time);\n",
    "plt.plot(x_ticks, val_pred_time);\n",
    "plt.title(\"Hyperparamter Testing: Training vs Validation Run Time\");\n",
    "# plt.ylabel('Prediction Accuracy');\n",
    "# plt.xlabel('Max Tree Depth');\n",
    "plt.legend(['Training', 'Validation']);\n",
    "plt.ylabel('Time (s)');\n",
    "plt.xlabel('Max Tree Depth');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2afff",
   "metadata": {},
   "source": [
    "Let's check the accuracy of a model with a depth of 25, since that is a reasonable run time on train (approximately 2.5 minutes), and that is where the validation accuracy seems to begin to level off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb90e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let't train a new model with the max tree depth of 28\n",
    "tree2 = DecisionTreeClassifier(max_depth=28)\n",
    "tree2.fit(X_train_np, train_target_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e93318",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy for train set\n",
    "train_pred = tree2.predict(X_train_np)\n",
    "total = len(train_pred)\n",
    "correct = 0\n",
    "\n",
    "for i in range(0, total):\n",
    "    if train_pred[i] == train_target_np[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy = {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7852a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy for val set\n",
    "pred2 = tree2.predict(X_val_np)\n",
    "\n",
    "total = len(pred2)\n",
    "correct = 0\n",
    "\n",
    "for i in range(0, total):\n",
    "    if pred2[i] == val_target_np[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy = {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5680222",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy for test set\n",
    "pred3 = tree2.predict(X_test_np)\n",
    "\n",
    "total = len(pred3)\n",
    "correct = 0\n",
    "\n",
    "for i in range(0, total):\n",
    "    if pred3[i] == test_target_np[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy = {correct/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2f3f1",
   "metadata": {},
   "source": [
    "### Using model to make predictions\n",
    "Finally, let's use the model to make some predictions. The first input should output a class of 1, signifiying a high suicide risk individual. The second prediction should result in an output of 0 for a low suicide risk individual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test input for prediction, hypothesis: high risk (1)\n",
    "test_input = {\n",
    "  'country': ['Republic of Korea'],\n",
    "    'year': [2020],\n",
    "    'sex': ['male'],\n",
    "    'age': ['75+ years'],\n",
    "    'suicides_no': [1400],\n",
    "    'population': [900000],\n",
    "    'suicides/100k pop': [155.55],\n",
    "    'gdp_for_year ($)': ['1,000,000,000'],\n",
    "    'gdp_per_capita ($)': [29000] \n",
    "}\n",
    "\n",
    "input_df = pd.DataFrame(test_input)\n",
    "input_df['age'][0]\n",
    "\n",
    "country_label = ['country_' + input_df['country'][0]]\n",
    "sex_label = ['sex_' + input_df['sex'][0]]\n",
    "age_label = ['age_' + input_df['age'][0]]\n",
    "\n",
    "#train_inputs.loc[train_inputs['age'] == input_df['age'][0]]\n",
    "\n",
    "# Use data from X_val to get the most similar entry and format input using those values\n",
    "norm_input = X_val.loc[(X_val[country_label[0]] ==  1) & (X_val[sex_label[0]] == 1) \n",
    "                               & (X_val[age_label[0]] == 1)]\n",
    "\n",
    "# Get most recent entry matching the important features\n",
    "test_input = norm_input.iloc[-1]\n",
    "\n",
    "test_input = test_input.to_numpy()\n",
    "\n",
    "test_input\n",
    "\n",
    "pred = tree2.predict([test_input])[0]\n",
    "print(\"Prediction for input: \", pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test input for prediction,  hypothesis: low risk (0)\n",
    "test_input = {\n",
    "  'country': ['Singapore'],\n",
    "    'year': [2020],\n",
    "    'sex': ['female'],\n",
    "    'age': ['15-24 years'],\n",
    "    'suicides_no': [14],\n",
    "    'population': [250000],\n",
    "    'suicides/100k pop': [5.6],\n",
    "    'gdp_for_year ($)': ['300,000,000,000'],\n",
    "    'gdp_per_capita ($)': [80000] \n",
    "}\n",
    "\n",
    "input_df = pd.DataFrame(test_input)\n",
    "input_df['age'][0]\n",
    "\n",
    "country_label = ['country_' + input_df['country'][0]]\n",
    "sex_label = ['sex_' + input_df['sex'][0]]\n",
    "age_label = ['age_' + input_df['age'][0]]\n",
    "\n",
    "# Use data from X_val to get the most similar entry and format input using those values\n",
    "norm_input = X_val.loc[(X_val[country_label[0]] ==  1) & (X_val[sex_label[0]] == 1) \n",
    "                               & (X_val[age_label[0]] == 1)]\n",
    "\n",
    "# Get most recent entry matching the important features\n",
    "test_input = norm_input.iloc[-1]\n",
    "\n",
    "test_input = test_input.to_numpy()\n",
    "\n",
    "test_input\n",
    "\n",
    "pred = tree2.predict([test_input])[0]\n",
    "print(\"Prediction for input: \", pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606193e",
   "metadata": {},
   "source": [
    "##### The model performed accurately, outputting expected results."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f24d7e647225f31d3a9608519da831f7054406feb44929f5d716b35557212e30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env-01')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
